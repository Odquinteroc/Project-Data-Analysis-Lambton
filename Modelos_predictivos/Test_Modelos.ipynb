{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias \n",
    "#redes neuronales\n",
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "#modelo arima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "#regresion lineal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#importar documentos\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#ignorar advertencias python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#medir tiemop\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importacion documentos\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Retrieve the MongoDB connection URI from the environment variables\n",
    "dbURI = os.getenv(\"MONGODB_URI\")\n",
    "# Connect to MongoDB using the connection URI\n",
    "client = pymongo.MongoClient(dbURI)\n",
    "# Access the \"Project\" database (it's not physically created until it has content)\n",
    "db = client['Project']\n",
    "#creacion datos capacidad\n",
    "collection = db['capacity']\n",
    "documents = collection.find()\n",
    "\n",
    "data = []\n",
    "for doc in documents:\n",
    "    province = doc[\"_id\"]\n",
    "    for energy_type, year_data in doc.items():\n",
    "        if energy_type != \"_id\":  # Skip the _id field\n",
    "            for year, value in year_data.items():\n",
    "                data.append({\n",
    "                    \"province\": province,\n",
    "                    \"energy type\": energy_type,\n",
    "                    \"year\": int(year),\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "#print(df)\n",
    "\n",
    "#creacion base de datos generacion\n",
    "collection1 = db['generation']\n",
    "documents1 = collection1.find()\n",
    "\n",
    "data1 = []\n",
    "for doc in documents1:\n",
    "    province = doc[\"_id\"]\n",
    "    for energy_type, year_data in doc.items():\n",
    "        if energy_type != \"_id\":  # Skip the _id field\n",
    "            for year, value in year_data.items():\n",
    "                data1.append({\n",
    "                    \"province\": province,\n",
    "                    \"energy type\": energy_type,\n",
    "                    \"year\": int(year),\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "#print(df1)\n",
    "\n",
    "#creacion base de datos capacidad por sector \n",
    "collection2 = db['capacity_by_sector']\n",
    "documents2 = collection2.find()\n",
    "\n",
    "data2 = []\n",
    "\n",
    "for document in documents2:\n",
    "    sector = document[\"_id\"]\n",
    "    # Iterate over each year in the document\n",
    "    for year in document:\n",
    "        if year != \"_id\" and isinstance(document[year], dict):  # Check if it's a year key and the value is a dictionary\n",
    "            # Access the subdocument for the year\n",
    "            year_data = document[year]\n",
    "            # Append a dictionary with the desired structure to the data list\n",
    "            data2.append({\n",
    "                \"sector\": sector,\n",
    "                \"year\": year,\n",
    "                \"UOM\": year_data[\"UOM\"],\n",
    "                \"value\": year_data[\"VALUE\"],\n",
    "                \"growth_percentage\": year_data.get(\"Grow_percentage\", None)  # Using .get() to handle missing data\n",
    "            })\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "##informacion de tabla precios\n",
    "collection3 = db['prices']\n",
    "documents3 = collection3.find()\n",
    "data3 = []\n",
    "\n",
    "for doc in documents3:\n",
    "    province = doc[\"_id\"]\n",
    "    # Iterate over each sector in the document\n",
    "    for sector, years in doc.items():\n",
    "        if sector != \"_id\":  \n",
    "            # Iterate over each year in the sector\n",
    "            for year, value in years.items():\n",
    "                data3.append({\n",
    "                    \"Province\": province,\n",
    "                    \"Sector\": sector,\n",
    "                    \"year\": int(year),\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "df3 = pd.DataFrame(data3)\n",
    "\n",
    "#importacion tabla demanda\n",
    "collection4 = db['demand']\n",
    "documents4 = collection4.find()\n",
    "data4 = []\n",
    "\n",
    "for doc in documents4:\n",
    "    province = doc[\"_id\"]\n",
    "    # Iterate over each sector in the document\n",
    "    for sector, years in doc.items():\n",
    "        if sector != \"_id\":  \n",
    "            # Iterate over each year in the sector\n",
    "            for year, value in years.items():\n",
    "                data4.append({\n",
    "                    \"Province\": province,\n",
    "                    \"Sector\": sector,\n",
    "                    \"year\": int(year),\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "df4 = pd.DataFrame(data4)\n",
    "\n",
    "#tabla de emisiones\n",
    "collection5 = db['emissions']\n",
    "documents5 = collection5.find()\n",
    "data5 = []\n",
    "\n",
    "for doc in documents5:\n",
    "    # The _id field here seems to represent a category rather than a province\n",
    "    category = doc[\"_id\"]\n",
    "    # Iterate over each year in the document\n",
    "    for year, value in doc.items():\n",
    "        if year != \"_id\":\n",
    "            data5.append({\n",
    "                \"Category\": category,\n",
    "                \"year\": int(year),\n",
    "                \"value\": value\n",
    "            })\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df5 = pd.DataFrame(data5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para calcular rsme con dataframes\n",
    "def cal_RMSE(val_reales, val_predichos):\n",
    "    val_reales = val_reales.values\n",
    "    val_predichos = val_predichos.values\n",
    "\n",
    "    mse = mean_squared_error(val_reales, val_predichos)\n",
    "\n",
    "    # Calcula el RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para calcular R2 con dataframes\n",
    "def cal_R2(val_reales, val_predichos):\n",
    "    # Asegurarse de que val_reales y val_predichos sean arrays de numpy\n",
    "    val_reales = val_reales.values\n",
    "    val_predichos = val_predichos.values\n",
    "\n",
    "    # Calcular R^2\n",
    "    r2 = r2_score(val_reales, val_predichos)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "#RED NEURONAL\n",
    "\n",
    "\n",
    "\n",
    "def Redneuronal(datas,periodos_validacion):\n",
    "    #Definicion parametros para ajustar ddatos entrada funcion\n",
    "    p = periodos_validacion\n",
    "    time_step = 3\n",
    "    largo_setvalidacion = p + time_step\n",
    "    largo_data = len(datas)\n",
    "    largo_setentrenamiento = largo_data - largo_setvalidacion\n",
    "    #Definicion set entrenamiento y validacion\n",
    "    set_entrenamiento = datas.iloc[:largo_setentrenamiento+1]\n",
    "    set_validacion = datas.iloc[largo_setentrenamiento:largo_data]\n",
    "\n",
    "    #Normalización del set de entrenamiento\n",
    "    sc = MinMaxScaler(feature_range=(0,1)) \n",
    "    set_entrenamiento_escalado = sc.fit_transform(set_entrenamiento) \n",
    "\n",
    "    #Definicion de parametros\n",
    "    #time_step = 3\n",
    "    X_train = [] \n",
    "    Y_train = []\n",
    "    m = len(set_entrenamiento_escalado) \n",
    "\n",
    "    #sets de entrenamiento\n",
    "    for i in range(time_step,m):\n",
    "        X_train.append(set_entrenamiento_escalado[i-time_step:i,0])\n",
    "        Y_train.append(set_entrenamiento_escalado[i,0])\n",
    "\n",
    "    #ajustes para el modelo keras\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    #Creacion red LSTM\n",
    "    dim_entrada = (X_train.shape[1],1)\n",
    "    dim_salida = 1\n",
    "    na = 500\n",
    "\n",
    "    modelo = Sequential()\n",
    "    modelo.add(LSTM(units=na, input_shape=dim_entrada))\n",
    "    modelo.add(Dense(units=dim_salida))\n",
    "\n",
    "    modelo.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "    modelo.fit(X_train,Y_train,epochs=200 ,batch_size=400, verbose=0)\n",
    "\n",
    "    #Validación (predicción del valor de la energia)\n",
    "    x_test = set_validacion.values\n",
    "    x_test = sc.transform(x_test)\n",
    "    X_test = []\n",
    "    for i in range(time_step,len(x_test)):\n",
    "        X_test.append(x_test[i-time_step:i,0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "    if len(X_test) > 0:\n",
    "        prediccion = modelo.predict(X_test)\n",
    "        prediccion = sc.inverse_transform(prediccion)\n",
    "    else:\n",
    "        print(\"No hay suficientes datos para generar predicciones.\")\n",
    "\n",
    "    #ajustes del largo\n",
    "    prediction_length = len(prediccion)\n",
    "    validation_length = len(set_validacion)\n",
    "    new_length = validation_length - prediction_length\n",
    "\n",
    "    adjusted_validation_set = set_validacion.iloc[new_length:].copy()\n",
    "    index_names = adjusted_validation_set.index\n",
    "\n",
    "    # Convert prediction to DataFrame and adjust the column name\n",
    "    prediction_df = pd.DataFrame(prediccion)\n",
    "    \n",
    "    #print(result)\n",
    "\n",
    "    #sacar RSME\n",
    "    val_RSME = cal_RMSE(adjusted_validation_set,prediction_df)\n",
    "\n",
    "  \n",
    "    return val_RSME , cal_R2(adjusted_validation_set,prediction_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Modelo Arima\n",
    "def ModeloArima(datas,periodos_validacion):\n",
    "    #arreglando dataset largo\n",
    "    set_entrenamiento = datas.head(len(datas)-periodos_validacion)\n",
    "    set_validacion = datas.tail(periodos_validacion)\n",
    "    #entrenamiento modelo arima\n",
    "    modelo = auto_arima(\n",
    "        set_entrenamiento,\n",
    "        start_p=1, start_q=1, max_p=12, max_q=12, d=None, # Especifica rangos para p, d, q\n",
    "         # Prueba 'adf' para encontrar el orden de diferenciación óptimo d, si no se especifica\n",
    "        seasonal=False,  # Asume estacionalidad con un ciclo anual, ajusta según tus datos\n",
    "        stepwise=True,\n",
    "        test='kpss',\n",
    "        suppress_warnings=True,\n",
    "        error_action=\"ignore\",\n",
    "        n_jobs=-1 # Utiliza todos los núcleos disponibles para la búsqueda\n",
    "    )\n",
    "    # Hacer un pronóstico para los próximos  años \n",
    "    pronostico = modelo.predict(n_periods=periodos_validacion)\n",
    " \n",
    "\n",
    "    #sacar RSME\n",
    "    val_RSME = cal_RMSE(set_validacion, pronostico)\n",
    "\n",
    "    return  val_RSME, cal_R2(set_validacion, pronostico)\n",
    "\n",
    "# ModeloArima(datafiltrada,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RegresionLineal(datas,periodos_validacion):\n",
    "    #df3 = pd.DataFrame()\n",
    "\n",
    "    X = datas.index.values.reshape(-1, 1)    #print(X)\n",
    "    Y = datas.values  # Variable dependiente\n",
    "\n",
    "    X_train = X[:-periodos_validacion]\n",
    "    X_test = X[-periodos_validacion:]\n",
    "    y_train = Y[:-periodos_validacion]\n",
    "    y_test = Y[-periodos_validacion:]\n",
    "\n",
    "    # Entrenamiento del modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicción para los años en el conjunto de prueba\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_predict =pd.DataFrame(y_predict)\n",
    "    #sacar RSME\n",
    "    set_validacion = datas[-periodos_validacion:]\n",
    "    val_RSME = cal_RMSE(set_validacion, y_predict)\n",
    "\n",
    "    return  val_RSME , cal_R2(set_validacion, y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_errores_optimizado(data, iterables2D, periodos):\n",
    "    resultados = []\n",
    "    #data['year'] = data['year'].astype(int)\n",
    "    #data['year'] = pd.to_datetime(data['year'], format='%Y')\n",
    "    \n",
    "    for i in data[iterables2D[0]].unique():\n",
    "        \n",
    "        for j in data[iterables2D[1]].unique():\n",
    "            # Filtra el DataFrame según las condiciones dadas\n",
    "            data_filtrada = data[(data[iterables2D[0]] == i) & (data[iterables2D[1]] == j)]\n",
    "\n",
    "            # Asegúrate de que la filtración no resulte en un DataFrame vacío\n",
    "            if not data_filtrada.empty:\n",
    "                # Selecciona solo las columnas de interés\n",
    "                datafiltrada = data_filtrada[[\"year\",\"value\"]]\n",
    "                datafiltrada = datafiltrada.set_index(\"year\")\n",
    "                datafiltrada.index.name = None\n",
    "    \n",
    "                # Llama a cada uno de los modelos y recopila sus resultados\n",
    "                RSME_ARI, R2_ARI = ModeloArima(datafiltrada, periodos)\n",
    "                RSME_RED, R2_RED = Redneuronal(datafiltrada, periodos)\n",
    "                RSME_RL, R2_RL = RegresionLineal(datafiltrada, periodos)\n",
    "                \n",
    "                # Crea un diccionario con todos los resultados y las etiquetas correspondientes\n",
    "                resultado_temporal = {\n",
    "                    iterables2D[0]: i, \n",
    "                    iterables2D[1]: j, \n",
    "                    'RSME_ARI': RSME_ARI, \n",
    "                    'R2_ARI': R2_ARI,\n",
    "                    'RSME_RED':RSME_RED,\n",
    "                    'R2_RED':R2_RED,\n",
    "                    'RSME_RL':RSME_RL,\n",
    "                    'R2_RL':R2_RL,\n",
    "                }\n",
    "                # Añade el diccionario a la lista de resultados\n",
    "                resultados.append(resultado_temporal)\n",
    "\n",
    "                \n",
    "\n",
    "    # Devuelve la lista de resultados\n",
    "    return resultados\n",
    "\n",
    "\n",
    "\n",
    "#-----------------\n",
    "def calcular_errores_optimizadouni(data, iterables2D, periodos):\n",
    "    resultados = []\n",
    "    #data['year'] = data['year'].astype(int)\n",
    "    #data['year'] = pd.to_datetime(data['year'], format='%Y')\n",
    "    \n",
    "    for i in data[iterables2D[0]].unique():\n",
    "        \n",
    "        data_filtrada = data[(data[iterables2D[0]] == i) ]\n",
    "\n",
    "        # Asegúrate de que la filtración no resulte en un DataFrame vacío\n",
    "        if not data_filtrada.empty:\n",
    "            # Selecciona solo las columnas de interés\n",
    "            datafiltrada = data_filtrada[[\"year\",\"value\"]]\n",
    "            datafiltrada = datafiltrada.set_index(\"year\")\n",
    "            datafiltrada.index.name = None\n",
    "\n",
    "            # Llama a cada uno de los modelos y recopila sus resultados\n",
    "            RSME_ARI, R2_ARI = ModeloArima(datafiltrada, periodos)\n",
    "            RSME_RED, R2_RED = Redneuronal(datafiltrada, periodos)\n",
    "            RSME_RL, R2_RL = RegresionLineal(datafiltrada, periodos)\n",
    "            \n",
    "            # Crea un diccionario con todos los resultados y las etiquetas correspondientes\n",
    "            resultado_temporal = {\n",
    "                iterables2D[0]: i,  \n",
    "                'RSME_ARI': RSME_ARI, \n",
    "                'R2_ARI': R2_ARI,\n",
    "                'RSME_RED':RSME_RED,\n",
    "                'R2_RED':R2_RED,\n",
    "                'RSME_RL':RSME_RL,\n",
    "                'R2_RL':R2_RL,\n",
    "            }\n",
    "            # Añade el diccionario a la lista de resultados\n",
    "            resultados.append(resultado_temporal)\n",
    "\n",
    "            \n",
    "\n",
    "    # Devuelve la lista de resultados\n",
    "    return resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_capacity = calcular_errores_optimizado(df,[\"province\",\"energy type\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_generation = calcular_errores_optimizado(df1,[\"province\",\"energy type\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prices = calcular_errores_optimizado(df3,[\"Province\",\"Sector\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_demand = calcular_errores_optimizado(df4,[\"Province\",\"Sector\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_emissions = calcular_errores_optimizadouni(df5,[\"Category\"], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_capacity_by_sector = calcular_errores_optimizadouni(df2,[\"sector\"], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_emissions\n",
    "# df_emissions = pd.DataFrame(df_emissions)\n",
    "# print(df_emissions)\n",
    "# #para emisiones redes neuronales\n",
    "# df_generation = pd.DataFrame(df_generation)\n",
    "# print(df_generation)\n",
    "# #para generacion redes neuronales\n",
    "# df_capacity_by_sector = pd.DataFrame(df_capacity_by_sector)\n",
    "# df_capacity_by_sector.groupby(\"sector\").sum()\n",
    "# df_capacity_by_sector\n",
    "# #para capacidad por redes neuronales\n",
    "# df_capacity\n",
    "# df_capacity = pd.DataFrame(df_capacity)\n",
    "# print(df_capacity)\n",
    "# #para capacidad redes neuronales\n",
    "# df_prices \n",
    "# df_prices = pd.DataFrame(df_prices)\n",
    "# print(df_prices.sum())\n",
    "# #para precios es arima\n",
    "# df_demand \n",
    "# df_demand = pd.DataFrame(df_demand)\n",
    "# print(df_demand.sum())\n",
    "# #para demanda es arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------------\n",
    "# creacion nueva red nuronal\n",
    "\n",
    "def RedNeuronalValFuturos(datas,periodos_a_predecir,time_step):\n",
    "\n",
    "    # Normalización de todo el conjunto de datos 'datas'\n",
    "    sc = MinMaxScaler(feature_range=(0, 1))\n",
    "    datas_escalado = sc.fit_transform(datas)\n",
    "\n",
    "    # Preparación de los datos de entrenamiento\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(time_step, len(datas_escalado)):\n",
    "        X_train.append(datas_escalado[i-time_step:i, 0])\n",
    "        Y_train.append(datas_escalado[i, 0])\n",
    "\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    # Definición y entrenamiento de la red LSTM\n",
    "    modelo = Sequential([\n",
    "        LSTM(500, input_shape=(time_step, 1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    modelo.compile(optimizer='rmsprop', loss='mse')\n",
    "    modelo.fit(X_train, Y_train, epochs=200, batch_size=400, verbose=0)\n",
    "\n",
    "    # Preparación para predicciones futuras\n",
    "    # Aquí asumimos que quieres generar predicciones continuando desde el final de 'datas'\n",
    "    ultimo_input = datas_escalado[-time_step:]\n",
    "    X_pred = np.array([ultimo_input])\n",
    "    X_pred = np.reshape(X_pred, (X_pred.shape[0], X_pred.shape[1], 1))\n",
    "\n",
    "    predicciones_futuras = []\n",
    "    for _ in range(periodos_a_predecir):\n",
    "        pred_nueva = modelo.predict(X_pred)[0]\n",
    "        predicciones_futuras.append(pred_nueva)\n",
    "        \n",
    "        # Actualiza 'X_pred' para incluir la nueva predicción al final y quitar el valor más antiguo al inicio\n",
    "        X_pred = np.append(X_pred, [[pred_nueva]], axis=1)\n",
    "        X_pred = X_pred[:, 1:, :]\n",
    "\n",
    "    # Inversión de la normalización para obtener valores reales\n",
    "    predicciones_futuras = sc.inverse_transform(predicciones_futuras)\n",
    "\n",
    "    # Conversión de las predicciones a un formato más legible/fácil de manejar, como un DataFrame\n",
    "    predicciones_df = pd.DataFrame(predicciones_futuras, columns=['Predicción'])\n",
    "    fechas = pd.date_range(start=\"2024\", end=f'{2024+periodos_a_predecir}', freq='A')\n",
    "    predicciones_df.index = fechas\n",
    "    return predicciones_df\n",
    "\n",
    "\n",
    "#----------------\n",
    "#aplicacion modelo por tabla\n",
    "def calcular_pronostico(data, iterables2D,periodos_a_predecir,time_step):\n",
    "    resultados = {\n",
    "        f'{iterables2D[0]}',\n",
    "        f'{iterables2D[1]}',\n",
    "    }\n",
    "\n",
    "    resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    for i in data[iterables2D[0]].unique():\n",
    "        \n",
    "        for j in data[iterables2D[1]].unique():\n",
    "            # Filtra el DataFrame según las condiciones dadas\n",
    "            data_filtrada = data[(data[iterables2D[0]] == i) & (data[iterables2D[1]] == j)]\n",
    "\n",
    "            # Asegúrate de que la filtración no resulte en un DataFrame vacío\n",
    "            if not data_filtrada.empty:\n",
    "                # Selecciona solo las columnas de interés\n",
    "                datafiltrada = data_filtrada[[\"year\",\"value\"]]\n",
    "                datafiltrada = datafiltrada.set_index(\"year\")\n",
    "                datafiltrada.index.name = None\n",
    "            \n",
    "            #configurar los index \n",
    "            resultado_temporal = {\n",
    "                iterables2D[0]: i, \n",
    "                iterables2D[1]: j, \n",
    "                'Pronostico': RedNeuronalValFuturos(datafiltrada,periodos_a_predecir,time_step)\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "            resultados.append(resultado_temporal)\n",
    "    # Devuelve la lista de resultados\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def calcular_pronosticouni(data, iterables2D,periodos_a_predecir,time_step):\n",
    "    resultados = []\n",
    "\n",
    "    for i in data[iterables2D[0]].unique():\n",
    "        # Filtra el DataFrame según las condiciones dadas\n",
    "        data_filtrada = data[(data[iterables2D[0]] == i)]\n",
    "\n",
    "        # Asegúrate de que la filtración no resulte en un DataFrame vacío\n",
    "        if not data_filtrada.empty:\n",
    "            # Selecciona solo las columnas de interés\n",
    "            datafiltrada = data_filtrada[[\"year\",\"value\"]]\n",
    "            datafiltrada = datafiltrada.set_index(\"year\")\n",
    "            datafiltrada.index.name = None\n",
    "        \n",
    "        #configurar los index \n",
    "        resultado_temporal = {\n",
    "            iterables2D[0]: i, \n",
    "            'Pronostico': RedNeuronalValFuturos(datafiltrada,periodos_a_predecir,time_step)\n",
    "        }\n",
    "\n",
    "        resultados.append(resultado_temporal)\n",
    "\n",
    "    # Devuelve la lista de resultados\n",
    "    return resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_capacity = calcular_errores_optimizado(df,[\"province\",\"energy type\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_generation = calcular_pronostico(df1,[\"province\",\"energy type\"],5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prices = calcular_pronostico(df3,[\"Province\",\"Sector\"],5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_demand = calcular_pronostico(df4,[\"Province\",\"Sector\"],5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "df_emissions = calcular_pronosticouni(df5,[\"Category\"],7,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_capacity_by_sector = calcular_pronosticouni(df2,[\"sector\"],5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Pronostico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>Predicción\n",
       "2024-12-31   15.400569\n",
       "...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>Predicción\n",
       "2024-12-31  554.759029\n",
       "...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                         Pronostico\n",
       "0  Electricity              Predicción\n",
       "2024-12-31   15.400569\n",
       "...\n",
       "1        Total              Predicción\n",
       "2024-12-31  554.759029\n",
       "..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emissions\n",
    "df_emissions = pd.DataFrame(df_emissions)\n",
    "df_emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>energy type</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Hydro / Wave / Tidal</td>\n",
       "      <td>2005</td>\n",
       "      <td>2316.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Hydro / Wave / Tidal</td>\n",
       "      <td>2006</td>\n",
       "      <td>1966.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Hydro / Wave / Tidal</td>\n",
       "      <td>2007</td>\n",
       "      <td>2113.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Hydro / Wave / Tidal</td>\n",
       "      <td>2008</td>\n",
       "      <td>2150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Hydro / Wave / Tidal</td>\n",
       "      <td>2009</td>\n",
       "      <td>1695.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Oil</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Oil</td>\n",
       "      <td>2020</td>\n",
       "      <td>75.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Oil</td>\n",
       "      <td>2021</td>\n",
       "      <td>79.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Oil</td>\n",
       "      <td>2022</td>\n",
       "      <td>82.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Oil</td>\n",
       "      <td>2023</td>\n",
       "      <td>98.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     province           energy type  year    value\n",
       "0     Alberta  Hydro / Wave / Tidal  2005  2316.00\n",
       "1     Alberta  Hydro / Wave / Tidal  2006  1966.00\n",
       "2     Alberta  Hydro / Wave / Tidal  2007  2113.00\n",
       "3     Alberta  Hydro / Wave / Tidal  2008  2150.00\n",
       "4     Alberta  Hydro / Wave / Tidal  2009  1695.00\n",
       "...       ...                   ...   ...      ...\n",
       "2104    Yukon                   Oil  2019     0.00\n",
       "2105    Yukon                   Oil  2020    75.33\n",
       "2106    Yukon                   Oil  2021    79.32\n",
       "2107    Yukon                   Oil  2022    82.18\n",
       "2108    Yukon                   Oil  2023    98.66\n",
       "\n",
       "[2109 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
